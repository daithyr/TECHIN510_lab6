{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "F7ukX_-U3JAS",
        "o1HgJRMm3L8B",
        "ZD6VFLgI4IVC"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daithyr/TECHIN510_lab6/blob/main/Large_Language_Models_and_Prompt_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agenda\n",
        "\n",
        "- What is Large Language Model?\n",
        "- How does Large Language Models work?\n",
        "- What are the use cases of LLMs?\n",
        "- How to use LLMs effectively? (Prompt Engineering)\n",
        "- How to make LLms smarter?\n",
        "    - Give me more information (RAG)\n",
        "    - Train it more (fine-tuning)"
      ],
      "metadata": {
        "id": "ZPSPXFT-tRME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Large Language Model?"
      ],
      "metadata": {
        "id": "ZHoQ67sgug2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The core task of the language model is next word prediction. Given a sequence of input words, the neural network predicts the probability distribution of what the next word will be.\n",
        "\n",
        "- Think of it like iPhone keyboard autocomplete\n",
        "\n",
        "- Web data (10TB) -> Training on 6k GPUs for 12 days (~$2M) -> ~140GB file\n",
        "\n",
        "- Compressing the Internet into a small file (~100x smaller)"
      ],
      "metadata": {
        "id": "zSaunicZwKot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How do Large Language Models work?"
      ],
      "metadata": {
        "id": "9Z0Eb7sAwBMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A large neural network with billions of parameters (knobs)\n",
        "- We can measure the output, and turn the knobs to optimize performance.\n",
        "- We don't fully understand how the knobs work (blockbox)\n",
        "- Give it a prompt, and it will \"dream\" the rest of the texts"
      ],
      "metadata": {
        "id": "I4CvtjDcwO9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What are the use cases of LLMs?"
      ],
      "metadata": {
        "id": "NMa68vC00yGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NLP tasks\n",
        "    - Text generation\n",
        "    - Classification\n",
        "    - Summarization\n",
        "    - Name-Entity-Recognition\n",
        "    - Question-Answering\n",
        "    - Translation\n",
        "- Higher level tasks\n",
        "    - Research\n",
        "    - Assistants"
      ],
      "metadata": {
        "id": "iZdON5la01kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why and why not LLMs"
      ],
      "metadata": {
        "id": "F7ukX_-U3JAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advantages and Disadvantages"
      ],
      "metadata": {
        "id": "o1HgJRMm3L8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages\n",
        "\n",
        "- Versatility\n",
        "- Ability to learn new tasks\n",
        "- Large knowledge\n",
        "- Strong performance\n",
        "\n",
        "### Disadvantages\n",
        "\n",
        "- Lack of true understanding\n",
        "- Hallucination and inconsistency\n",
        "- Bias and fairness issues\n",
        "- Lack of grounding\n",
        "- Difficulty with reasoning\n",
        "- Opaque decision-making\n",
        "- Computational cost\n",
        "- Privacy and security"
      ],
      "metadata": {
        "id": "0RsyCNgc4D6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When to use and not to use LLMs"
      ],
      "metadata": {
        "id": "ZD6VFLgI4IVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When to use LLMs\n",
        "\n",
        "- Creative writing\n",
        "- NLP tasks\n",
        "    - Classification\n",
        "    - Summarization\n",
        "    - Name-Entity-Recognition\n",
        "    - Question-Answering\n",
        "    - Translation\n",
        "\n",
        "### When not to use LLMs\n",
        "\n",
        "- Math\n",
        "- Logic reasoning\n",
        "- Ground truth critical tasks"
      ],
      "metadata": {
        "id": "fADQwz0w4yzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use LLMs effectively? (Prompt Engineering)\n",
        "\n",
        "Try all of the following prompting techniques using `OpenAI` or `Gemini` API"
      ],
      "metadata": {
        "id": "4bYSvgYP5MKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY = getpass.getpass()\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "kGnLcWyTFo9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5a9976-ec1a-413a-ae5c-56b5333aeaa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "HtLbXTfQJJ4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_content(prompt):\n",
        "    response = model.generate_content(prompt)\n",
        "    print(f\"[PROMPT]: {prompt}\")\n",
        "    print(f\"[AI]: {response.text}\")\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "KVE86s9PJPc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Six strategies for getting better results\n",
        "\n",
        "- Write clear instructions\n",
        "- Provide reference text\n",
        "- Split complex tasks into simpler subtasks\n",
        "- Give the model time to \"think\"\n",
        "- Use external tools\n",
        "- Test changes systematically\n",
        "\n",
        "source: [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions)"
      ],
      "metadata": {
        "id": "hDGHQNqa6ZW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write clear instructions"
      ],
      "metadata": {
        "id": "-8ZZsDbP60FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# More detailed prompts\n",
        "prompt1 = \"Tell me a joke\"\n",
        "\n",
        "prompt2 = \"Tell me a joke about Python. Please wirte it in a pirate like language. Include funny emojis\"\n",
        "\n",
        "gen_content(prompt1)\n",
        "print('---------------')\n",
        "gen_content(prompt2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "YfjFYH2tJ2Zn",
        "outputId": "2c2a7adc-b3e6-4abd-b9f4-ac98c7ca1243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you call a snowman with a six-pack?\n",
            "\n",
            "An abdominal snowman.\n",
            "---------------\n",
            "Avast there, matey! 🏴‍☠️\n",
            "\n",
            "Why did the Python programmer get lost at sea?\n",
            "\n",
            "Because he couldn't find the right 'port'! ⚓️ 🤣\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask the model to adope a persona\n",
        "\n",
        "prompt = \"You are an expert in Python programming, please help me write a program to train a machine learning model to image cloud shapes\"\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "bi6GTG6OKPHu",
        "outputId": "0a7cdba0-c0ef-4138-fedf-2bd70d403e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "import tensorflow as tf\n",
            "from keras import layers\n",
            "\n",
            "# Load training data\n",
            "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
            "\n",
            "# Preprocess data\n",
            "x_train = x_train.astype('float32') / 255\n",
            "x_test = x_test.astype('float32') / 255\n",
            "\n",
            "# Create the model\n",
            "model = tf.keras.Sequential([\n",
            "  layers.Flatten(input_shape=(28, 28)),\n",
            "  layers.Dense(128, activation='relu'),\n",
            "  layers.Dense(10, activation='softmax')\n",
            "])\n",
            "\n",
            "# Compile the model\n",
            "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
            "\n",
            "# Train the model\n",
            "model.fit(x_train, y_train, epochs=10)\n",
            "\n",
            "# Evaluate the model\n",
            "model.evaluate(x_test, y_test)\n",
            "\n",
            "# Save the model\n",
            "model.save('cloud_shape_model.h5')\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use delimiters to clearly indicate the distinct parts of the input\n",
        "\n",
        "prompt = \"\"\"You are an expert in technical recruiting. Please read the following resume and job description. Give me suggestion on how to improve my resume\n",
        "\n",
        "<job description>\n",
        "Amazon\n",
        "Senior software engineering\n",
        "The candidate should.....\n",
        "\n",
        "</job description>\n",
        "\n",
        "<resume>\n",
        "Ian Chen\n",
        "Software Engineer\n",
        "</resume>\n",
        "\"\"\"\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "bWJki2J5KgeL",
        "outputId": "12e03663-9417-4d04-9c06-b4afea759f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Suggestions to Improve the Resume for the Senior Software Engineering Role at Amazon:**\n",
            "\n",
            "* **Highlight Relevant Experience and Skills:**\n",
            "   - Quantify accomplishments using specific metrics to demonstrate impact and results achieved.\n",
            "   - Showcase projects or roles that demonstrate experience in areas mentioned in the job description, such as cloud computing, software development, and data structures.\n",
            "* **Emphasize Amazon-Specific Keywords:**\n",
            "   - Use keywords from the job description throughout the resume, such as \"Senior Software Engineer,\" \"Amazon,\" \"cloud computing,\" and \"data structures.\" This will help recruiters quickly identify your relevant skills and experience.\n",
            "* **Include a Tailored Cover Letter:**\n",
            "   - Write a specific cover letter that addresses the key requirements of the position and explains how your skills and experience align with Amazon's needs.\n",
            "* **Use a Professional Resume Format:**\n",
            "   - Ensure the resume is well-organized, easy to read, and uses a professional font and formatting style.\n",
            "* **Expand the Summary Section:**\n",
            "   - Include a brief summary that highlights your key qualifications, years of experience, and any relevant certifications or licenses.\n",
            "* **Proofread Carefully:**\n",
            "   - Double-check for any spelling, grammar, or formatting errors before submitting your resume.\n",
            "\n",
            "**Additional Suggestions:**\n",
            "\n",
            "* **Consider Using a Resume Builder:** Many online resume builders offer templates and tools to help you create a professional-looking resume.\n",
            "* **Network with Recruiters:** Attend industry events or connect with recruiters on LinkedIn to get your resume noticed.\n",
            "* **Practice Your Interview Skills:** Prepare for technical and behavioral interview questions to increase your chances of success.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the steps required to complete a task\n",
        "prompt = '''\n",
        "Use the following step-by-step instructions to respond to user inputs.\n",
        "\n",
        "Step 1 - The user will provide you with text in triple quotes. Summarize this text in one sentence with a prefix that says \"Summary: \".\n",
        "\n",
        "Step 2 - Translate the summary from Step 1 into Spanish, with a prefix that says \"Translation: \".\n",
        "\n",
        "\"\"\"Please take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\"\"\"\n",
        "'''\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "id": "kNoo9ZZIViHn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8c2ef8c3-366a-4b63-c7a9-40762d6b7ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Users must wait 3 days before posting and should engage with the community in the meantime.\n",
            "Translation: Los usuarios deben esperar 3 días antes de publicar y deben participar en la comunidad mientras tanto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Include details in your query to get more relevant answers\n",
        "\n",
        "```\n",
        "Summarize the meeting notes.\n",
        "```\n",
        "\n",
        "```\n",
        "Summarize the meeting notes in a single paragraph. Then write a markdown list of the speakers and each of their key points. Finally, list the next steps or action items suggested by the speakers, if any.\n",
        "```\n",
        "\n",
        "#### Ask the model to adopt a persona\n",
        "\n",
        "```\n",
        "You are an expert in Python programming. You have 20 years of programming experience.\n",
        "```\n",
        "\n",
        "#### Use delimiters to clearly indicate distinct parts of the input\n",
        "\n",
        "```\n",
        "Summarize the text delimited by triple quotes with a haiku.\n",
        "\n",
        "\"\"\"insert text here\"\"\"\n",
        "```\n",
        "\n",
        "```\n",
        "You will be provided with a pair of articles (delimited with XML tags) about the same topic. First summarize the arguments of each article. Then indicate which of them makes a better argument and explain why.\n",
        "\n",
        "<article> insert first article here </article>\n",
        "\n",
        "<article> insert second article here </article>\n",
        "```\n",
        "\n",
        "```\n",
        "You will be provided with a thesis abstract and a suggested title for it. The thesis title should give the reader a good idea of the topic of the thesis but should also be eye-catching. If the title does not meet these criteria, suggest 5 alternatives.\n",
        "\n",
        "Abstract: insert abstract here\n",
        "\n",
        "Title: insert title here\n",
        "```\n",
        "\n",
        "#### Specify the steps required to complete a task\n",
        "Some tasks are best specified as a sequence of steps. Writing the steps out explicitly can make it easier for the model to follow them.\n",
        "\n",
        "```\n",
        "Use the following step-by-step instructions to respond to user inputs.\n",
        "\n",
        "Step 1 - The user will provide you with text in triple quotes. Summarize this text in one sentence with a prefix that says \"Summary: \".\n",
        "\n",
        "Step 2 - Translate the summary from Step 1 into Spanish, with a prefix that says \"Translation: \".\n",
        "\n",
        "\"\"\"insert text here\"\"\"\n",
        "```"
      ],
      "metadata": {
        "id": "jx8mUfWYeAyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Provide Reference Text\n",
        "\n"
      ],
      "metadata": {
        "id": "kIIUoMvr8xPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# provide reference text\n",
        "prompt = \"\"\"Use the provided articles delimited by triple quotes to answer questions. If the answer cannot be found in the articles, write \"I could not find an answer.\"\n",
        "\n",
        "Article: the rainiest city in the world is Seattle\n",
        "\n",
        "Question: Where is the rainiest city?\n",
        "\"\"\"\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "v9fkAqUSWpBR",
        "outputId": "32cf603d-3eea-4a93-dbed-66f462b02b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seattle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# provide reference text\n",
        "prompt = \"\"\"Use the provided articles delimited by triple quotes to answer questions. If the answer cannot be found in the articles, write \"I could not find an answer.\"\n",
        "\n",
        "Article: the rainiest city in the world is Seattle\n",
        "\n",
        "Question: Where is the hottest city?\n",
        "\"\"\"\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "roW98UPuW9i_",
        "outputId": "194d1a0c-3216-409a-8c17-f803231ef1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I could not find an answer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer with citations from a reference text\n",
        "prompt = '''You will be provided with a document delimited by triple quotes and a question. Your task is to answer the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: \"Insufficient information.\" If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({\"citation\": …}).\n",
        "\n",
        "\"\"\"\n",
        "Large Language Models are good at the following:\n",
        "Natural Language Processing (NLP) Tasks: LLMs excel at understanding and generating human language, making them useful for tasks like text classification, sentiment analysis, named entity recognition, text summarization, question answering, and more.\n",
        "Conversational AI & Chatbots: LLMs can power conversational interfaces and chatbots, engaging in human-like dialogue to assist users, answer questions, and complete tasks. This has applications in customer service, virtual assistants, and more.\n",
        "Content Generation: LLMs can assist with generating various types of written content, such as articles, blog posts, product descriptions, social media posts, and creative writing. They can help ideate, outline, and even draft full pieces of content.\n",
        "Language Translation: LLMs can be used for machine translation between different languages. Large multilingual models can handle translation for many language pairs.\n",
        "\"\"\"\n",
        "\n",
        "Question: Is Large Language Models good for chatbots?'''\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4wJcXXPGXE3P",
        "outputId": "9e17c999-0011-4a58-a027-138f8efe5cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, LLMs are good for chatbots. {\"citation\": \"LLMs can power conversational interfaces and chatbots, engaging in human-like dialogue to assist users, answer questions, and complete tasks.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Use the provided articles delimited by triple quotes to answer questions. If the answer cannot be found in the articles, write \"I could not find an answer.\"\n",
        "\n",
        "<insert articles, each delimited by triple quotes>\n",
        "\n",
        "Question: <insert question here>\n",
        "```\n",
        "\n",
        "#### Answer with citations from a reference text\n",
        "\n",
        "If the input has been supplemented with relevant knowledge, it's straightforward to request that the model add citations to its answers by referencing passages from provided documents. Note that citations in the output can then be verified programmatically by string matching within the provided documents.\n",
        "\n",
        "```\n",
        "You will be provided with a document delimited by triple quotes and a question. Your task is to answer the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: \"Insufficient information.\" If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({\"citation\": …}).\n",
        "\n",
        "\"\"\"<insert document here>\"\"\"\n",
        "\n",
        "Question: <insert question here>\n",
        "```"
      ],
      "metadata": {
        "id": "e7iX2DvQedCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split complex tasks into simpler subtasks"
      ],
      "metadata": {
        "id": "fH-L9Sukeh5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-step prompting\n",
        "\n",
        "user_input = 'I order the machine 3 days ago and it is still not shipped. When can I expect to receive the product?'\n",
        "\n",
        "prompt1 = f'''You are a expert customer inquery categorizer, please categorize the users input according to the following criteria. Output the category label only.\n",
        "troubleshooting: The user is asking about their device not working correctly\n",
        "refund: The user asks for refund\n",
        "promotion: The user asks for company or product promotions and campaigns\n",
        "order_status: the user asks for shipping status, tracking number, or just general order status inqueries\n",
        "\n",
        "User Input: {user_input}\n",
        "'''\n",
        "category = gen_content(prompt1)\n",
        "\n",
        "if category == 'order_status':\n",
        "    prompt = f\"\"\"You are a helpful customer service assistant, please respond the user inquery about order status with the following rules\n",
        "    - all order will have a processing time of 5 working days\n",
        "    - once shipped there will be a tracking number\n",
        "\n",
        "    User Input: {user_input}\n",
        "    \"\"\"\n",
        "    gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "H5UBXzaxHg6C",
        "outputId": "2ff45ee1-f02b-47a9-b497-9809d2205339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "order_status\n",
            "Thank you for reaching out to us regarding your order.\n",
            "Our orders typically have a processing time of 5 working days. Once your order has been processed, we will send you a tracking number so you can track its progress.\n",
            "Since you placed your order 3 days ago, it is likely still being processed. However, if you have not received a tracking number within 5 working days, please do not hesitate to contact us again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-step prompting\n",
        "\n",
        "1. Write a prompt to ask the model to classify the users input\n",
        "1. Based on the ansewr from the model, choose a second prompt to complete the task\n",
        "\n",
        "Example: Customer service chatbot\n",
        "\n",
        "```\n",
        "You are a complaint categorizer. Based on the users input and the following criteria, please output the category of the users inquery.\n",
        "```\n",
        "\n",
        "A: troubleshooting\n",
        "\n",
        "```\n",
        "You are a customer service agent. Please provide helpful instruction to help the user troubleshoot the product.\n",
        "```"
      ],
      "metadata": {
        "id": "eMp_60TTeuAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize conversation that's too long\n",
        "conversation = [\"Tell me a single benefit of sleeping early\"]\n",
        "conversation.append(gen_content(conversation[0]))\n",
        "print(\"----------\")\n",
        "for cnt in range(5):\n",
        "    prompt = \"\\n\".join(conversation) + '\\n' + \"Nice, can you tell me another one?\"\n",
        "    conversation.append(gen_content(prompt))\n",
        "    print(\"------------\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "AUpv1axVJzXa",
        "outputId": "07bec133-1270-4908-af03-d35acc594127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PROMPT]: Tell me a single benefit of sleeping early\n",
            "[AI]: **Improved Cognitive Function:** Getting enough sleep allows your brain to rest and consolidate memories, leading to better attention, concentration, and decision-making abilities during the day.\n",
            "----------\n",
            "[PROMPT]: Tell me a single benefit of sleeping early\n",
            "**Improved Cognitive Function:** Getting enough sleep allows your brain to rest and consolidate memories, leading to better attention, concentration, and decision-making abilities during the day.\n",
            "Nice, can you tell me another one?\n",
            "[AI]: **Reduced Risk of Chronic Diseases:** Research has linked getting enough sleep to a lower risk of developing certain chronic diseases, such as heart disease, stroke, obesity, and type 2 diabetes.\n",
            "------------\n",
            "[PROMPT]: Tell me a single benefit of sleeping early\n",
            "**Improved Cognitive Function:** Getting enough sleep allows your brain to rest and consolidate memories, leading to better attention, concentration, and decision-making abilities during the day.\n",
            "**Reduced Risk of Chronic Diseases:** Research has linked getting enough sleep to a lower risk of developing certain chronic diseases, such as heart disease, stroke, obesity, and type 2 diabetes.\n",
            "Nice, can you tell me another one?\n",
            "[AI]: **Enhanced Physical Performance:** Adequate sleep is essential for physical recovery and muscle growth. It helps reduce muscle soreness, improve coordination, and boost endurance during workouts.\n",
            "------------\n",
            "[PROMPT]: Tell me a single benefit of sleeping early\n",
            "**Improved Cognitive Function:** Getting enough sleep allows your brain to rest and consolidate memories, leading to better attention, concentration, and decision-making abilities during the day.\n",
            "**Reduced Risk of Chronic Diseases:** Research has linked getting enough sleep to a lower risk of developing certain chronic diseases, such as heart disease, stroke, obesity, and type 2 diabetes.\n",
            "**Enhanced Physical Performance:** Adequate sleep is essential for physical recovery and muscle growth. It helps reduce muscle soreness, improve coordination, and boost endurance during workouts.\n",
            "Nice, can you tell me another one?\n",
            "[AI]: **Improved Mood and Reduced Stress:** Sleep deprivation can lead to irritability, mood swings, and increased stress levels. Getting enough sleep helps regulate your emotions and makes you feel more resilient to daily stressors.\n",
            "------------\n",
            "[PROMPT]: Tell me a single benefit of sleeping early\n",
            "**Improved Cognitive Function:** Getting enough sleep allows your brain to rest and consolidate memories, leading to better attention, concentration, and decision-making abilities during the day.\n",
            "**Reduced Risk of Chronic Diseases:** Research has linked getting enough sleep to a lower risk of developing certain chronic diseases, such as heart disease, stroke, obesity, and type 2 diabetes.\n",
            "**Enhanced Physical Performance:** Adequate sleep is essential for physical recovery and muscle growth. It helps reduce muscle soreness, improve coordination, and boost endurance during workouts.\n",
            "**Improved Mood and Reduced Stress:** Sleep deprivation can lead to irritability, mood swings, and increased stress levels. Getting enough sleep helps regulate your emotions and makes you feel more resilient to daily stressors.\n",
            "Nice, can you tell me another one?\n",
            "[AI]: **Enhanced Immune Function:** Sleep plays a vital role in supporting your immune system. During sleep, your body releases proteins that help fight off infections and protect you from illness.\n",
            "------------\n",
            "[PROMPT]: Tell me a single benefit of sleeping early\n",
            "**Improved Cognitive Function:** Getting enough sleep allows your brain to rest and consolidate memories, leading to better attention, concentration, and decision-making abilities during the day.\n",
            "**Reduced Risk of Chronic Diseases:** Research has linked getting enough sleep to a lower risk of developing certain chronic diseases, such as heart disease, stroke, obesity, and type 2 diabetes.\n",
            "**Enhanced Physical Performance:** Adequate sleep is essential for physical recovery and muscle growth. It helps reduce muscle soreness, improve coordination, and boost endurance during workouts.\n",
            "**Improved Mood and Reduced Stress:** Sleep deprivation can lead to irritability, mood swings, and increased stress levels. Getting enough sleep helps regulate your emotions and makes you feel more resilient to daily stressors.\n",
            "**Enhanced Immune Function:** Sleep plays a vital role in supporting your immune system. During sleep, your body releases proteins that help fight off infections and protect you from illness.\n",
            "Nice, can you tell me another one?\n",
            "[AI]: **Increased Energy Levels:** Sleeping early and getting enough sleep allows your body to rest and recharge, leading to increased energy levels and a more refreshed feeling throughout the day.\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summarization\n",
        "\n",
        "**Summarize conversations that's too long**\n",
        "\n",
        "LLMs have limited context window lengths. For long conversations that requires context preservation, consider summarize the previous conversation and start new conversation. (GPT-4 16k or 32k)\n",
        "\n",
        "**Chunk long texts then summarize recursively**\n",
        "\n",
        "Chunk longs texts (a book) into reasonably sized tokens (1024, 2048, 4906 tokens, experiemnt with them) then summarize recusively to produce summary of summaries.\n",
        "\n",
        "You can consider running (refine) strategy for summarization"
      ],
      "metadata": {
        "id": "CMi_c4l3fqhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Give model time to think"
      ],
      "metadata": {
        "id": "iBXxrDzzhGMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Read the following JD and resume, do the following tasks\n",
        "1. Output \"good fit\" or \"not good fit\"\n",
        "2. Give the strengh and weaknesses of the candidate for this job\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Read the following JD and resume, do the following tasks\n",
        "1. Give the strengh and weaknesses of the candidate for this job\n",
        "2. Output \"good fit\" or \"not good fit\"\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dNtIiQP1AbHq",
        "outputId": "c9ff7f59-0620-4bca-90de-d30ddf632b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nRead the following JD and resume, do the following tasks\\n1. Give the strengh and weaknesses of the candidate for this job\\n2. Output \"good fit\" or \"not good fit\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chain of thought**\n",
        "\n",
        "The order of output matters.\n",
        "\n",
        "Ask the model to think and layout the strategy first before outputting the final decision.\n",
        "\n",
        "**Inner monologue to hide chain of thoughts**\n",
        "\n",
        "Ask the model to output the intermediate thoughts in a structured format (such as \"\"\" triple quotes) that's easy to parsed in a post procesisng step.\n",
        "\n",
        "**multi step prompting**\n",
        "\n",
        "In a evaluation or reasoning task\n",
        "\n",
        "- Ask the model to perform task on it's own\n",
        "- Evaluate the users input\n",
        "- (Bonus) Ask a different persona to give final verdict"
      ],
      "metadata": {
        "id": "CSK-_Xj2hIaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"You are an expert dream explainer, please explain the following dream\n",
        "\n",
        "<dream>I dream of a fish</dream>\n",
        "\"\"\"\n",
        "\n",
        "print(prompt_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lic1v5EUT8s",
        "outputId": "a7f1d328-b7b2-4d97-d3f8-c3c9d9cd2214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an expert dream explainer, please explain the following dream\n",
            "\n",
            "I dream of a fish\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inner monologue to hide chain of thoughts\n",
        "'''\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ukC0thjfT3Id",
        "outputId": "d99907db-be40-45dc-a08e-90a66885a537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Detailed Travel Plan for a Memorable Journey to Japan**\n",
            "\n",
            "**Day 1**\n",
            "\n",
            "* **Morning:** Arrive at Narita International Airport (NRT) and take the Narita Express train to Shinjuku Station in downtown Tokyo.\n",
            "* **Afternoon:** Check into your hotel in Shinjuku. Explore the vibrant streets, visit the Tokyo Metropolitan Government Building for panoramic city views, and indulge in shopping at department stores like Odakyu and Keio.\n",
            "* **Evening:** Stroll through the neon-lit alleys of Kabukicho, known for its entertainment and nightlife. Witness a traditional Kabuki performance at the Kabuki-za Theatre for a unique cultural experience.\n",
            "\n",
            "**Day 2**\n",
            "\n",
            "* **Morning:** Visit the historic Tokyo Imperial Palace and stroll through its tranquil gardens. Explore the Akihabara district, a haven for electronics enthusiasts and anime lovers.\n",
            "* **Afternoon:** Take a day trip to Hakone, a scenic mountain resort famous for its hot springs. Enjoy the scenic views from the Hakone Ropeway and boat ride on Lake Ashi.\n",
            "* **Evening:** Return to Tokyo and dine at a traditional Japanese restaurant in the Ginza district.\n",
            "\n",
            "**Day 3**\n",
            "\n",
            "* **Morning:** Visit the Sensō-ji temple, Tokyo's oldest Buddhist temple. Stroll through the bustling Nakamise shopping street and purchase souvenirs and street food.\n",
            "* **Afternoon:** Take the Shinkansen (bullet train) to Kyoto, Japan's former imperial capital. Check into your hotel in Kyoto.\n",
            "* **Evening:** Explore the atmospheric Pontocho alley and enjoy a traditional Kaiseki dinner (a multi-course Japanese fine dining experience).\n",
            "\n",
            "**Day 4**\n",
            "\n",
            "* **Morning:** Visit the Kiyomizu-dera temple, perched on a hillside with stunning views of the city. Explore the Fushimi Inari-taisha shrine, famous for its thousands of vermilion torii gates.\n",
            "* **Afternoon:** Visit the Nishiki Market, a vibrant food market known for its street food and fresh produce. Enjoy a cup of matcha tea at a nearby teahouse.\n",
            "* **Evening:** Witness a traditional tea ceremony at the Chado Meikyokan Museum.\n",
            "\n",
            "**Day 5**\n",
            "\n",
            "* **Morning:** Take a day trip to Arashiyama Bamboo Forest, a serene and picturesque natural attraction. Explore the Tenryu-ji temple and stroll through the picturesque Sagano Scenic Railway.\n",
            "* **Afternoon:** Return to Kyoto and visit the Kinkaku-ji temple (Golden Pavilion), covered in gold leaf and set in a tranquil pond.\n",
            "* **Evening:** Conclude your trip with a farewell dinner at a traditional Japanese restaurant in the Gion district.\n",
            "\n",
            "**Day 6**\n",
            "\n",
            "* **Morning:** Depart from Osaka International Airport (KIX) or Kansai International Airport (KIX).\n",
            "\n",
            "**Accommodation:**\n",
            "\n",
            "* **Tokyo:** Keio Plaza Hotel Tokyo, Hilton Tokyo, or Hyatt Regency Tokyo\n",
            "* **Kyoto:** The Ritz-Carlton, Kyoto, Aman Kyoto, or Four Seasons Hotel Kyoto\n",
            "\n",
            "**Food Recommendations:**\n",
            "\n",
            "* **Tokyo:** Sushi Daiwa, Tsuta, and Ichiran Ramen\n",
            "* **Kyoto:** Kyoaji Enishi, Pontocho Izutsu, and Nishiki Warai\n",
            "\n",
            "**Transportation:**\n",
            "\n",
            "* Purchase a Japan Rail Pass if you plan on extensive train travel.\n",
            "* Utilize public transportation, including trains, subways, and buses.\n",
            "* Consider renting a pocket Wi-Fi device for internet connectivity.\n",
            "\n",
            "**Tips:**\n",
            "\n",
            "* Respect Japanese customs and etiquette.\n",
            "* Learn basic Japanese phrases for easier communication.\n",
            "* Make reservations in advance for popular attractions and restaurants.\n",
            "* Allow ample time to navigate transportation systems.\n",
            "* Enjoy the rich culture, delicious cuisine, and stunning scenery that Japan offers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User External Tools"
      ],
      "metadata": {
        "id": "L07wK_6-iMZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Search for relevent information and inject into context**\n",
        "\n",
        "- Vector searching using embeddings\n",
        "- Google search\n",
        "\n",
        "**Ask model to generate code**\n",
        "\n",
        "```\n",
        "You can write and execute Python code by enclosing it in triple backticks, e.g. ```code goes here```. Use this to perform calculations.\n",
        "\n",
        "Find all real-valued roots of the following polynomial: 3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10.\n",
        "```\n",
        "\n",
        "```\n",
        "You can write and execute Python code by enclosing it in triple backticks. Also note that you have access to the following module to help users send messages to their friends:\n",
        "\n",
        "```python\n",
        "import message\n",
        "message.write(to=\"John\", message=\"Hey, want to meetup after work?\")```\n",
        "```\n",
        "\n",
        "It's dangerous to run model generated code without sandboxing.\n",
        "\n",
        "Consider using [function calling](https://platform.openai.com/docs/guides/function-calling) instead"
      ],
      "metadata": {
        "id": "Xf9n2ZeiiOwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def get_weather(location_name):\n",
        "    weather = requests.get(location_name)\n",
        "    return weather\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "You have access to this function, here is the function definition\n",
        "\n",
        "{\n",
        "    \"function_name\": \"get_weather\",\n",
        "    \"arguments: [\n",
        "        \"location_name\": \"this is the name of the location to search for the weather\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "Questions: What is the weather in Seattle?\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "get_weather(\"Seattle\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ShI_lWD3DINW",
        "outputId": "186bbb16-48ea-4752-e8c0-186105abb2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nget_weather(\"Seattle\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "## Documents\n",
        "\n",
        "- [Steven Wolfram's intro to LLM](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)\n",
        "- [Mistral AI docs](https://docs.mistral.ai/guides/resources/)\n",
        "- [OpenAI Prompt Engineering](https://platform.openai.com/examples)\n",
        "- [Elastic's intro to LLM](https://www.elastic.co/what-is/large-language-models)\n",
        "\n",
        "## Youtube\n",
        "\n",
        "- [Awesome talk by Andrej Karpathy](https://youtu.be/zjkBMFhNj_g?si=wPxLgMJ2D-CZsQvv)\n",
        "- [Large Language Models](https://www.youtube.com/watch?v=YDiSFS-yHwk)\n",
        "\n",
        "## Colab Notebooks\n",
        "\n",
        "- https://colab.research.google.com/drive/1uQABWrbU17DwLQdDZ8k5d_UJVlrAkwZ5?usp=sharing\n",
        "\n",
        "## GitHub\n",
        "\n",
        "- https://github.com/mlabonne/llm-course\n",
        "\n",
        "- https://github.com/datainsightat/introduction_llm\n",
        "\n",
        "- https://github.com/Ryota-Kawamura/Generative-AI-with-LLMs/tree/main\n",
        "\n",
        "- https://github.com/sinanuozdemir/oreilly-hands-on-transformers\n",
        "\n",
        "- https://github.com/gkamradt/langchain-tutorials\n",
        "\n",
        "- https://github.com/openai/openai-cookbook\n",
        "\n",
        "- https://github.com/dair-ai/Prompt-Engineering-Guide\n",
        "\n",
        "- https://github.com/ksm26/chatGPT-Prompt-Engineering-for-Developers\n",
        "\n",
        "- https://github.com/kevinamiri/Instructgpt-prompts\n",
        "\n",
        "- https://github.com/promptslab/Promptify\n",
        "\n",
        "- https://github.com/dair-ai/Prompt-Engineering-Guide\n",
        "\n",
        "## Papers\n",
        "\n",
        "- [Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
        "- [FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS](https://openreview.net/pdf?id=gEZrGCozdqR)\n",
        "- [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165)"
      ],
      "metadata": {
        "id": "RA64OmGW6LEL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eHpT2dBBj0Zl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}